<!DOCTYPE html>
<html lang="en-us">

<head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FGXNM2XG5R"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FGXNM2XG5R');
    </script>
    
    <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "Corporation",
            "name": "Air Street Capital",
            "logo": "https://github.com/nathanbenaich/airstreet/raw/master/Air%20Street%20Capital%20logo%20(blue).png",
            "description": "Air Street Capital is a venture capital firm investing in AI-first technology and life science companies",
            },
            "founder": {
                "@type": "Person",
                "name": ["Nathan Benaich"]
            },
            "url": "http://www.airstreet.com/",
            "knowsAbout": ["machine learning", "deep technology", "deep learning", "early stage startups", "artificial intelilgence", "reinforcement learning", "enterprise software", "SaaS", "software-as-a-service", "fundraising", "venture capital", "generative ai", "spinouts"],
            "legalName": "Air Street Capital Management Ltd.",
            "slogan": "Air Street Capital is a venture capital firm investing in AI-first technology and life science companies"
        }
    </script>
    <meta charset="UTF-8">
    <title>Staying the course - reflections ahead of the UK's AI Safety Summit</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <link rel="icon" href="favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=PT+Sans:400,700" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <meta name="description" content="Air Street Capital is a venture capital firm investing in AI-first technology and life science companies.">
    <meta name="keywords" content="venture capital, investing, technology, VC, investment, funding, point nine capital, air street capital, artificial intelligence, machine learning, deep learning, intelligent systems, research, startups, life science, biology, chemistry, biotechnology, computer vision, natural language processing, SaaS, early-stage startup, VC funding">
    <link rel="icon" href="https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAVtAAAAJDYzNTBjMDFjLWE4Y2ItNDI2NC04ZmE3LTRiZWJiZWNhOWJkNA.jpg" type="image/jpg" sizes="32x32">
    <meta name="author" content="Air Street Capital">

    <!-- for Twitter -->
    <meta name="twitter:card" content="summary_large_image" />
    <!-- changed this to summary_large_image to have a large share picture -->
    <meta name="twitter:site" content="@airstreet" />
    <meta name="twitter:creator" content="@airstreet" />
    <meta property="twitter:title" content="China has no place at the AI Safety Summit" />
    <meta property="twitter:description" content="We argue that democratic nations have little to gain from involving a hostile government with a track record of subverting international institutions." />
    <meta property="twitter:image" content="https://www.airstreet.com/blog/china-ai-safety-summit.png" />

    <!-- for linkedin -->
    <meta property="og:url" content="https://www.airstreet.com/blog/china-ai-safety-summit" />
    <meta property="og:title" content="China has no place at the AI Safety Summit" />
    <meta property="og:description" content="We argue that democratic nations have little to gain from involving a hostile government with a track record of subverting international institutions."
    />
    <meta property="og:image" content="https://www.airstreet.com/blog/china-ai-safety-summit.png">
    <meta property="og:type" content="article" />

    <!-- Added to have cool social share buttons -->
    <!-- Bulma-Social -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-social@1/bin/bulma-social.min.css">
    <!-- Font Awesome 5 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

    <!-- Google schema -->
    <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "Person",
            "name": "Nathan Benaich",
            "affiliation": {
                "@type": "Corporation",
                "name": "Air Street Capital"
            },
            "alumniOf": {
                "@type": "Corporation",
                "name": "Point Nine Capital"
            },
            "colleagues": {
                "@type": "Person",
                "name": ["Paula Pastor Castano"]
            },
            "hasOccupation": {
                "@type": "Occupation",
                "description": "Venture capital investor"
            },
            "knowsAbout": ["State of AI Report", "generative ai", "techbio", "artificial intelligence", "deep learning", "machine learning", "reinforcement learning", "supervised learning", "startups", "venture capital", "State of AI", "investing", "early stage investing", "SaaS", "software-as-a-service", "spinouts"],
            "description": "Nathan Benaich is the Founder of Air Street Capital, a venture capital firm investing in startups using artificial intelligence to build products for consumers and enterprises",
            "url": "https://www.nathanbenaich.com"
        }
    </script>

</head>

<body>

    <section class="page-header">
        <div class="hero-body">
            <div class="container has-text-centered">
                <div class='card equal-height logo-container'>
                    <div class='card-image'>
                        <nav class="level">
                            <div class="level-item has-text-centered">
                                <div class="container">
                                    <a href="/">
                                        <img class="logo" alt="Air Street logo" src='logo.png'>
                                    </a>
                                    <div class="project-tagline"><b>Word on Air Street</b>.</div>
                                </div>
                            </div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <a href="/blog" class="button is-white is-outlined"> üè° Blog home</a>
            <a href="/portfolio" class="button is-white is-outlined"> ü¶Ñ Portfolio</a>
            <a href="/team" class="button is-white is-outlined"> üëã Team</a>
            <a href="https://nathanbenaich.substack.com/?utm_source=airstreet-web&utm_medium=website&utm_campaign=airstreet-blog/" class="button is-white is-outlined" target="_blank"> ‚úâÔ∏è Newsletter</a>
            <a href="https://www.stateof.ai//?utm_source=airstreet-web&utm_medium=website&utm_campaign=airstreet-blog" class="button is-white is-outlined" target="_blank"> üìñ State of AI</a>
            <a href="/shop" class="button is-white is-outlined"> üõçÔ∏è Merch</a>
    </section>

    <section class="main-content">
        <h2>
            <a id="about-me" class="anchor" href="#blog" aria-hidden="true"><span class="octicon octicon-link"></span></a>China has no place at the AI Safety Summit</h2>

        <p><i>Published by Alex Chalmers and Nathan Benaich on 31 August 2023.</i></p>

        <a class="button is-normal is-twitter" style="text-decoration: none;" href="https://twitter.com/intent/tweet?url=https://www.airstreet.com/blog/china-ai-safety-summit/&text=The+UK+Government+appears+to+be+changing+course+and+preparing+to+invite+China+to+participate+in+the+AI+Safety+Summit.+Calls+for+China‚Äôs+involvement+ultimately+illustrate+the+lack+of+seriousness+we+see+at+the+heart+of+proposals+for+global+AI governance."
            target="_blank">
            <span class="icon">
                <i class="fab fa-twitter"></i>
              </span>
        </a>

        <a class="button is-normal is-linkedin" style="text-decoration: none;" href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.airstreet.com/blog/china-ai-safety-summit/&title=The+UK+Government+appears+to+be+changing+course+and+preparing+to+invite+China+to+participate+in+the+AI+Safety+Summit.+Calls+for+China‚Äôs+involvement+ultimately+illustrate+the+lack+of+seriousness+we+see+at+the+heart+of+proposals+for+global+AI governance."
            target="_blank">
            <span class="icon">
                <i class="fab fa-linkedin"></i>
              </span>
        </a>

<br>
<br>

        <p>
            <i><b>Tl;dr:</b></i> As the UK‚Äôs AI Safety Summit draws nearer, the UK Government appears to be changing course and preparing to invite China to participate. We argue that democratic nations have little to gain from involving a hostile government with a track record of subverting international institutions, especially considering that they have yet to agree on many of the issues at stake. Calls for China‚Äôs involvement ultimately illustrate the lack of seriousness we see at the heart of proposals for global AI governance. 
        </p>

        <h3>Introduction</h3>

        <p>
            Ahead of the UK‚Äôs AI Safety Summit, we‚Äôve seen speculation about the guestlist mount. Initially, the UK suggested that only ‚Äúlike-minded‚Äù governments would be invited to attend, but it appears to have backed away from this position. It was reported <a href="https://www.politico.eu/article/china-likely-at-uk-ai-summit-despite-pushback-from-allies/" target="_blank">last week</a> that, over the objections of the EU, US, and Japan, China will likely be present ‚Äúin some capacity‚Äù, potentially on the sidelines of the conference. 
        </p>

        <p>        
            Before this apparent change of heart, there had been a coalition spanning the AI research and political worlds calling for China to be invited. For example, Tobias Ellwood, chair of the Commons Defence Select Committee, <a href="https://www.independent.co.uk/news/uk/politics/china-ai-summit-tory-mps-b2354010.html" target="_blank">drew parallels</a> with the international regulation of nuclear power, arguing that: <i>‚ÄúIf we don‚Äôt have total buy-in from the start the dangers of AI over humans is given space to develop and any threat won‚Äôt be contained by geographical borders.‚Äù</i>
        </p>

        <p>
            In the AI community, Huw Roberts, a DPhil student at the Oxford Internet Institute <a href="https://www.ft.com/content/3829707c-b93e-4715-bc7e-4de917e76914" target="_blank">wrote a letter</a> to the Financial Times making a similar case around risk transcending borders. Roberts also argued that as China was ahead of the UK and US on AI regulation, its experience <i>‚Äúwould be invaluable for informing well-designed policy at the UK‚Äôs AI summit‚Äù</i>. A number of participants at a <a href="https://www.governance.ai/post/what-should-the-global-summit-on-ai-safety-try-to-accomplish" target="_blank">recent workshop</a> held by the Centre for the Governance of AI warned that the summit might be the only opportunity to involve China in governance discussions and that China was more likely to engage with frameworks it felt it had helped to create.
        </p>

        <p>
            In our view, these calls for China‚Äôs inclusion at the summit are misguided for three key reasons:
        </p>

            <li>China is pursuing an approach to AI regulation that is motivated less by a sincere commitment to safety and more by political control;</li>
            <li>China has a long history of attempting to subvert multilateral institutions and technical standards;</li>
            <li>‚ÄòGlobal governance‚Äô is currently a pipe dream, so democratic nations should focus on reaching agreements among themselves.</li>

        <h3>Preserving the social order: China and AI regulation</h3>

        <p>
            From the moment the 2016 Lee Sedol-AlphaGo challenge match placed AI well and truly on the radar of the Chinese government, it has viewed AI through an intensely political lens. The People‚Äôs Liberation Army quickly <a href="https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ&dbname=CJFDLAST2017&filename=XKSJ201605020&uid=WEEvREcwSlJHSldRa1Fhb09jMjQxRHNaYW52d0hCV1owVnNuUDZDSHBFUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!&v=MzAzNDNVUkwyZlllWnFGQ2prVTd6UFBTYllaTEc0SDlmTXFvOUhaSVI4ZVgxTHV4WVM3RGgxVDNxVHJXTTFGckM=" target="_blank">held seminars</a> to discuss its significance, and China raced ahead of the world in setting national strategies and <a href="https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117" target="_blank">passing AI regulation</a>. We saw high-level governance regulations appearing as early as 2017, before a series of specific regulations appeared over 2020-2021 around online algorithms. 
        </p>

        <p>
            According to Matt Sheehan, a China specialist at the Carnegie Endowment for International Peace, this early focus on algorithms was not a coincidence. Sheehan <a href="https://carnegieendowment.org/files/202307-Sheehan_Chinese%20AI%20gov.pdf" target="_blank">argues</a> that: <i>‚ÄúThe first, overriding goal is to shape the technology so it serves the CCP‚Äôs [Chinese Communist Party] agenda, particularly for information control, and following from this, political and social stability.‚Äù</i> 
        </p>

        <p>
            This prioritisation of ‚Äòstability‚Äô above all else is visible on even a superficial reading. For example, the <a href="https://digichina.stanford.edu/work/translation-internet-information-service-deep-synthesis-management-provisions-draft-for-comment-jan-2022/" target="_blank">2022 Deep Synthesis Regulation</a> is replete with references to <i>‚Äúcorrect political direction‚Äù, ‚Äúsocial morals‚Äù,</i> the need to <i>‚Äúaccept social supervision‚Äù,</i> and a prohibition on sharing <i>‚Äúinformation inciting subversion of State power‚Äù</i>. The <a href="https://digichina.stanford.edu/work/translation-measures-for-the-management-of-generative-artificial-intelligence-services-draft-for-comment-april-2023/" target="_blank">latest regulations on generative AI</a> drive home how content <i>‚Äúshall reflect the Socialist Core Values, and may not contain: subversion of state power, overturning of the socialist system ‚Ä¶ as well as content that may upset economic order or social order‚Äù</i>. In the same obvious category go the prohibitions on ‚Äòfalse information‚Äô and the requirements for people signing up to AI content generation platforms to supply their real names.
        </p>

        <p>
            Even if there might be individual privacy protections, clauses around liability, or other individual points western commentators like individually, it‚Äôs impossible to separate these from the wider philosophy behind the regulation. We saw the same process unfold with China‚Äôs <a href="https://thechinaproject.com/big-tech-crackdown-timeline/" target="_blank">2021-2023 ‚ÄúBig Tech'' clampdown</a> (which also attracted <a href="https://www.theguardian.com/commentisfree/2021/oct/09/china-is-cutting-its-tech-giants-down-to-size-should-the-west-learn-from-this" target="_blank">western admirers</a>), where the ‚Äòpublic interest‚Äô was used as a cover for a power grab. As data and privacy expert Jamie Susskind <a href="https://www.wired.co.uk/article/china-big-tech-regulation" target="_blank">has observed</a>: <i>‚ÄúWhen we start being starry-eyed about the Chinese model of enforcement, we've lost track of the fact that regulation isn't just supposed to rein in private companies, it's also supposed to limit the power of the state.‚Äù</i>
        </p>

        <p>
            Even if we put all these concerns to the side and accept that the theory behind Chinese regulation could be interesting, we turn to the question of its implementation.
        </p>

        <p>
            Authoritarian states have a long history of managing risk dismally. Bill Drexel and Hannah Kelley at the Centre for a New American Security <a href="https://www.foreignaffairs.com/china/china-flirting-ai-catastrophe" target="_blank">have documented</a> the CCP‚Äôs <i>‚Äúdisaster amnesia‚Äù</i>, which results in the government burying bad news, suppressing death tolls from accidents, and rarely learning from mistakes. The <a href="https://www.nytimes.com/2020/02/01/world/asia/china-coronavirus.html" target="_blank">suppression</a> of early warning signs from doctors about Covid-19 combined with a <a href="https://www.washingtonpost.com/world/asia_pacific/conspiracy-theorists-blame-the-us-for-coronavirus-china-is-happy-to-encourage-them/2020/03/05/50875458-5dc8-11ea-ac50-18701e14e06d_story.html" target="_blank">disinformation campaign</a> about its origins wasn‚Äôt an isolated example. It was preceded by a four-month cover-up of the 2002 SARS outbreak and multi-year suppression of reports of HIV-contaminated blood transfusions in the 1990s.
        </p>

        <p>
            Considering the <a href="https://www.bbc.co.uk/news/technology-57101248">well</a>-<a href="https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html" target="_blank">documented</a> <a href="https://www.washingtonpost.com/technology/2020/12/08/huawei-tested-ai-software-that-could-recognize-uighur-minorities-alert-police-report-says/" target="_blank">use</a> of AI by the authorities in Xinjiang to enforce and deepen its repression of the Uighur population, it‚Äôs clear the CCP has no interest in abiding by the strictures on AI use it sets for the private sector.
        </p>

        <p>
            China may well adopt the form of AI regulation, but magic words about responsible AI do nothing to bring the substance into being and we should seriously question whether they would have any interest in acting as an honest partner on AI safety.  
        </p>

        <h3>‚ÄúCyber sovereignty‚Äù: China and international governance</h3>

        <p>
            China‚Äôs domestic attitude to technology is indicative of its international approach, with the government happy to violate agreements and attempt to subvert multilateral bodies. Were China to be a participant in discussions around global AI governance, we have no reason to believe that it would either comply with their outcome and every reason to believe that they would attempt to shape them in an authoritarian direction.
        </p>

        <p>
            The recent past is littered with precedent. We see this, for example, in the World Trade Organisation, where China is still in <a href="https://ustr.gov/about-us/policy-offices/press-office/press-releases/2023/february/ustr-releases-annual-report-chinas-wto-compliance" target="_blank">clear violation</a> of the many open market commitments it made as a condition of membership in 2001. There have also been more subtle efforts in less well-known international bodies. Perhaps the most striking is China‚Äôs <a href="https://foreignpolicy.com/2023/08/25/china-wants-to-run-your-internet/" target="_blank">multi-year effort</a> to change internet standards. China has attempted to move internet standards away from multistakeholder bodies to the purview of the UN‚Äôs International Telecommunication Union (ITU), where only member states can participate in negotiations. 
        </p>

        <p>
            China unsuccessfully pushed for a former Huawei executive to be installed as the ITU‚Äôs Secretary General in 2022 and has used Huawei to advocate for a new internet protocol that would radically centralise the internet. The New IP, as it‚Äôs dubbed, would allow network operators to see the content of any information being shared, as well as identify the sender and receiver. Network operators would also gain the power to block delivery. Unsurprisingly, Russia, Iran, and Saudi Arabia are its biggest international champions.
        </p>

        <p>
            China also <a href="https://www.aei.org/wp-content/uploads/2022/03/Pletka-ITU-edited.pdf?x91208" target="_blank">attempts strong-arm tactics</a> in the ITU‚Äôs daily operations. This includes forcing company delegates participating in study groups to take their phones into the voting booth to prove they‚Äôre voted ‚Äòcorrectly‚Äô or instructing them to deliberately obstruct the work of groups until they agree to Chinese proposals (e.g. on 5G standards).
        </p>

        <p>
            Fortunately, many of these efforts have not been successful so far as democracies have rallied to block them, but we should not underestimate China‚Äôs determination to export its model of governance. We‚Äôve seen it <a href="https://freedomhouse.org/article/east-african-states-adopt-chinas-playbook-internet-censorship" target="_blank">forge close ties</a> with repressive East African states, providing money and expertise to governments looking to mimic its censorship of the internet and social media. It also established the World Internet Conference, in partnership with Russia and other authoritarian states, in an effort to legitimise its model of <a href="https://www.bbc.co.uk/news/world-asia-china-35109453" target="_blank">‚Äúcyber sovereignty‚Äù</a>. Giving a flavour of the proceedings, the draft communiqu√© for the inaugural conference was <a href="https://www.wsj.com/articles/BL-CJB-24963" target="_blank">slipped under delegates‚Äô hotel room doors</a> after midnight and anyone with suggested changes was given until 8am the next morning to supply feedback.
        </p>

        <p>
            China‚Äôs philosophy of international governance is to take every possible opportunity, however clumsily, to legitimise and export its model of domestic repression - it would be naive to expect anything approaching good faith engagement in AI governance. 
        </p>

        <h3>‚ÄúGlobal governance‚Äù: frameworks or fan fiction?</h3>


        <p>
            This same naivety underpins many of the proposals for global AI governance. Based on the evidence we‚Äôve seen, there‚Äôs little reason to believe that any kind of substantive global architecture is possible, or necessarily desirable at the current time, despite the growing range of frameworks emerging from researchers and entrepreneurs. 
        </p>

        <p>
            At a basic level, there seems to be little agreement about what we should be attempting to govern. Are we aiming to prevent catastrophic risk, seeking to establish global standards around equitable and sustainable AI use, or broaden access to AI? Or all of the above? These are all different remits that require different approaches. 
        </p>

        <p>
            The debate is further muddied by an alphabet soup of acronyms, with people variously reaching for the International Atomic Energy Authority, CERN, the Intergovernmental Panel on Climate Change, and others as inspiration. Beyond a conceptual fuzziness, the practicalities of then implementing any framework is usually treated as an after-thought.
        </p>

        <p>
            To take a recent example, Mustafa Suleyman (CEO and Co-Founder of Inflection AI) and Ian Bremmer (President of the Eurasia Group) <a href="https://www.foreignaffairs.com/world/artificial-intelligence-power-paradox" target="_blank">co-wrote</a> an essay for Foreign Affairs outlining their views on governance. They propose a <i>‚Äútechnoprudential mandate‚Äù</i>, which is designed to <i>‚Äúaddress the various aspects of AI that could threaten geopolitical stability‚Äù</i>. 
        </p>

        <p>
            However, ‚Äògeopolitical stability‚Äô is a slippery concept and is used to justify giving this hypothetical regime a seemingly limitless mandate, including: overseeing the entire AI value chain; improving US-China relations; governing open source AI (via online censorship if necessary); fighting disinformation and privacy violations; and convening ‚Äòcivil society‚Äô and the tech sector. Bremmer and Suleyman lay out no path to how the necessary institutions would come into being, beyond a throwaway acknowledgement that <i>‚Äúnone of these solutions will be easy to implement‚Äù</i>. That‚Äôs to say nothing of the desirability of placing China at the heart of this Leviathan.
        </p>

        <p>
            Perhaps the most rigorous attempt to explore different models comes in the form of a <a href="https://arxiv.org/abs/2307.04699" target="_blank">recent paper</a> from Lewis Ho, a researcher at Google DeepMind, written with collaborators from OpenAI and a range of leading universities. Lewis and his co-authors essentially accept that different priorities require different institutions, and each has its costs, implicitly suggesting political choice is required. They propose four options and are upfront about the scoping challenges and issues around incentivising international participation. As a result, they stop short of endorsing any one of these approaches and acknowledge that while more international cooperation is needed, we are not ready to commit to a model.
        </p>

        <p>
            Considering this total lack of agreement on the right starting point for governance among even AI experts in democratic nations, inviting a motivated adversary with a clear philosophy seems reckless. In this context, a forum of ‚Äúlike-minded‚Äù nations is exactly what‚Äôs needed.
        </p>

        <h3>Unlearning the lessons of the past?</h3>


        <p>
            As the UK Government eyes potential rapprochement with China internationally, it‚Äôs vital we don‚Äôt ignore the flashing red lights on the dashboard. These include:
        </p>

        <li> <a href="https://www.spectator.co.uk/article/british-universities-took-24-million-from-china/" target="_blank">Tens of millions of pounds</a> flowing from Chinese state institutions into UK universities; </li>
        <li>UK universities and research institutes <a href="https://www.civitas.org.uk/publications/inadvertently-arming-china-one-year-on/" target="_blank">unintentionally hiring staff</a> from Chinese defence conglomerates and conducting research sponsored by Chinese ICBM manufacturers;</li>
        <li>UK universities <a href="https://www.newstatesman.com/politics/2021/07/how-chinese-government-buying-its-way-uk-universities" target="_blank">self-censoring</a> on subjects like Tibet or the treatment of the Uighurs; </li>
        <li>The People‚Äôs Liberation Army <a href="https://www.cnbc.com/2022/10/18/chinas-military-is-trying-to-recruit-ex-british-air-force-pilots-for-training-and-intel-uk-says.html#:~:text=in%20a%20statement.-,Some%2030%20former%20British%20military%20pilots%20are%20believed%20to%20have,to%20work%20for%20the%20Chinese." target="_blank">hiring</a> ex-Royal Air Force pilots to train its military;</li>
        <li>Widespread <a href="https://www.thetimes.co.uk/article/uk-government-china-threat-security-tt9trw03b" target="_blank">Chinese control</a> of the UK‚Äôs civil nuclear sector.</li>

<br>

        <p>
            Last year, Parliament‚Äôs Intelligence and Security Committee painted a <a href="https://isc.independent.gov.uk/wp-content/uploads/2023/07/ISC-China.pdf" target="_blank">damning picture</a> of how <i>‚ÄúChina‚Äôs size, ambition and capability have enabled it to successfully penetrate every sector of the UK‚Äôs economy, and - until the Covid-19 pandemic, Chinese money was readily accepted by HMG with few questions asked‚Äù</i>. Few in the British political class like to remember the official discussion of the <a href="https://www.reuters.com/article/us-china-britain-idUSKCN0SB10M20151017" target="_blank">‚Äúgolden era‚Äù</a> in UK-China relations as recently as 2015.
        </p>

        <p>
            While some in the tech sector may not like the rhetoric of an ‚Äòarms race‚Äô, renaming it doesn‚Äôt make it go away. As we‚Äôve seen in the case of the ITU, when democracies fight back against interference, they can be successful. But when short-term economic gain or idealistic hopes of the global community win out, we find ourselves in much more treacherous waters. If democracies delegate the nascent and confused AI governance debate to an amorphous global forum, there is a high risk that it will be hijacked. We may well end up discovering that the road to ‚ÄúAI sovereignty‚Äù is paved with good intentions.
        </p>



      <footer class="site-footer">
        <span class="site-footer-credits">
          &copy; 2023 Air Street Capital Management Ltd., all rights reserved. 
          <p><a href="https://www.twitter.com/airstreet" target="_blank"><u>Twitter</u></a> | <a href="https://www.linkedin.com/company/airstreetcapital/" target="_blank"><u>LinkedIn</u></a></p>
      </footer>
    </section>
  </body>
</html>