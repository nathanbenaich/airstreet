<!DOCTYPE html>
<html lang="en-us">

<head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FGXNM2XG5R"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FGXNM2XG5R');
    </script>
    
    <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "Corporation",
            "name": "Air Street Capital",
            "logo": "https://github.com/nathanbenaich/airstreet/raw/master/Air%20Street%20Capital%20logo%20(blue).png",
            "description": "Air Street Capital is a venture capital firm investing in AI-first technology and life science companies",
            },
            "founder": {
                "@type": "Person",
                "name": ["Nathan Benaich"]
            },
            "url": "http://www.airstreet.com/",
            "knowsAbout": ["machine learning", "deep technology", "deep learning", "early stage startups", "artificial intelilgence", "reinforcement learning", "enterprise software", "SaaS", "software-as-a-service", "fundraising", "venture capital", "generative ai", "spinouts"],
            "legalName": "Air Street Capital Management Ltd.",
            "slogan": "Air Street Capital is a venture capital firm investing in AI-first technology and life science companies"
        }
    </script>
    <meta charset="UTF-8">
    <title>House of Lords on UK LLMs</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <link rel="icon" href="favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=PT+Sans:400,700" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <meta name="description" content="Air Street Capital is a venture capital firm investing in AI-first technology and life science companies.">
    <meta name="keywords" content="venture capital, investing, technology, VC, investment, funding, point nine capital, air street capital, artificial intelligence, machine learning, deep learning, intelligent systems, research, startups, life science, biology, chemistry, biotechnology, computer vision, natural language processing, SaaS, early-stage startup, VC funding">
    <link rel="icon" href="https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAVtAAAAJDYzNTBjMDFjLWE4Y2ItNDI2NC04ZmE3LTRiZWJiZWNhOWJkNA.jpg" type="image/jpg" sizes="32x32">
    <meta name="author" content="Air Street Capital">


    <!-- for Twitter -->
    <meta name="twitter:card" content="summary_large_image" />
    <!-- changed this to summary_large_image to have a large share picture -->
    <meta name="twitter:site" content="@airstreet" />
    <meta name="twitter:creator" content="@airstreet" />
    <meta property="twitter:title" content="House of Lords on UK LLMs" />
    <meta property="twitter:description" content="My witness notes for the House of Lords Communications and Digital Committee inquiry on LLMs."
    />
    <meta property="twitter:image" content="https://www.airstreet.com/blog/lords.png">


    <!-- for linkedin -->
    <meta property="og:url" content="https://www.airstreet.com/blog/lords-uk-llm-opportunity" />
    <meta property="og:title" content="House of Lords on UK LLMs" />
    <meta property="og:description" content="My witness notes for the House of Lords Communications and Digital Committee inquiry on LLMs."
    />
    <meta property="og:image" content="https://www.airstreet.com/blog/lords.png">
    <meta property="og:type" content="article" />
    <!-- Added to have cool social share buttons -->
    <!-- Bulma-Social -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-social@1/bin/bulma-social.min.css">
    <!-- Font Awesome 5 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

    <!-- Google schema -->
    <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "Person",
            "name": "Nathan Benaich",
            "affiliation": {
                "@type": "Corporation",
                "name": "Air Street Capital"
            },
            "alumniOf": {
                "@type": "Corporation",
                "name": "Point Nine Capital"
            },
            "colleagues": {
                "@type": "Person",
                "name": ["Paula Pastor Castano"]
            },
            "hasOccupation": {
                "@type": "Occupation",
                "description": "Venture capital investor"
            },
            "knowsAbout": ["State of AI Report", "generative ai", "techbio", "artificial intelligence", "deep learning", "machine learning", "reinforcement learning", "supervised learning", "startups", "venture capital", "State of AI", "investing", "early stage investing", "SaaS", "software-as-a-service", "spinouts"],
            "description": "Nathan Benaich is the Founder of Air Street Capital, a venture capital firm investing in startups using artificial intelligence to build products for consumers and enterprises",
            "url": "https://www.nathanbenaich.com"
        }
    </script>

</head>

<body>

    <section class="page-header">
        <div class="hero-body">
            <div class="container has-text-centered">
                <div class='card equal-height logo-container'>
                    <div class='card-image'>
                        <nav class="level">
                            <div class="level-item has-text-centered">
                                <div class="container">
                                    <a href="/">
                                        <img class="logo" alt="Air Street logo" src='logo.png'>
                                    </a>
                                    <div class="project-tagline"><b>Word on Air Street</b>.</div>
                                </div>
                            </div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <a href="/blog" class="button is-white is-outlined"> üè° Blog home</a>
            <a href="/portfolio" class="button is-white is-outlined"> ü¶Ñ Portfolio</a>
            <a href="/team" class="button is-white is-outlined"> üëã Team</a>
            <a href="https://nathanbenaich.substack.com/?utm_source=airstreet-web&utm_medium=website&utm_campaign=airstreet-blog/" class="button is-white is-outlined" target="_blank"> ‚úâÔ∏è Newsletter</a>
            <a href="https://www.stateof.ai//?utm_source=airstreet-web&utm_medium=website&utm_campaign=airstreet-blog" class="button is-white is-outlined" target="_blank"> üìñ State of AI</a>
            <a href="/shop" class="button is-white is-outlined"> üõçÔ∏è Merch</a>
    </section>

    <section class="main-content">
        <h2>
            <a id="about-me" class="anchor" href="#blog" aria-hidden="true"><span class="octicon octicon-link"></span></a>The UK LLM opportunity: Air Street at the House of Lords</h2>

        <p><i>Published by Nathan Benaich on 28 Sept 2023.</i></p>

        <a class="button is-normal is-twitter" style="text-decoration: none;" href="https://twitter.com/intent/tweet?url=https://www.airstreet.com/blog/lords-uk-llm-opportunity/&text=My+witness+notes+for+the+%40LordsCommsCom+inquiry+on+the+UK+and+LLMs"
            target="_blank">
            <span class="icon">
                <i class="fab fa-twitter"></i>
              </span>
        </a>

        <a class="button is-normal is-linkedin" style="text-decoration: none;" href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.airstreet.com/blog/lords-uk-llm-opportunity/&title=My+witness+notes+for+the+%40LordsCommsCom+inquiry+on+the+UK+and+LLMs"
            target="_blank">
            <span class="icon">
                <i class="fab fa-linkedin"></i>
              </span>
        </a>

        <h3>AI and the Future of Britain</h3>
        <p>
            The House of Lords Communications and Digital Committee is currently <a href="https://committees.parliament.uk/work/7827/large-language-models/" target="_blank">holding an inquiry</a> into Large Language Models (LLMs) and the steps governments, businesses, and regulators need to take over the next 1-3 years to maximize the opportunities while minimizing the risks.
        </p>

        <p>
            Alongside Peter Waggett (IBM), Zoe Webster (BT), and Francesco Marconi (Applied XL), I was invited to give evidence on the potential benefits of LLMs to the UK economy and the barriers to investment.
        </p>

        <p>
            I‚Äôve tidied up the notes I prepared ahead of time, grouped under the main themes of the session. There‚Äôs also some extra material in there that we didn‚Äôt have time to cover. You can watch the session in full <a href="https://committees.parliament.uk/event/19327/formal-meeting-oral-evidence-session/" target="_blank">here</a>.
        </p>

        <h3>Discussion areas</h3>

        <h4>
            <b>Where is the LLM opportunity in the UK?</b>
        </h4>

        <li>
            The UK AI startups that have raised the most money have reflected either areas of the UK‚Äôs innate advantage or the effects of government policy. That‚Äôs why we have such high concentrations of investment in cybersecurity, the life sciences, and fintech. 
        </li>

        <li>
            There are opportunities for the use of generative AI in all of these. I‚Äôm personally most excited by the life sciences - both in terms of the positive impact on humanity and the tie in with the UK‚Äôs strong research base.
        </li>

        <li>
            I‚Äôve already come across businesses in the US that are using generative AI to support protein design, which could support the development of new therapeutics. 
        </li>

        <li>
            There‚Äôs also the possibility of models being used to analyze chemical libraries to help us generate novel molecular structures that bind to certain proteins - making drug discovery faster and cheaper.
        </li>

        <li>
            Much of the expertise required to do this work is currently trapped in our universities, which is why I‚Äôm glad the UK government is pursuing its review of spinout policy.
        </li>

        <li>
            At the same time, we should avoid becoming too self-congratulatory. The UK is strong by European standards, but lagging global leaders:

            <ol style="list-style-type: lower-alpha; padding-bottom: 0;">
                <li style="margin-left:2em">Between 2019-2023, the Bay Area alone saw $6B invested in Generative AI (excluding OpenAI), while London saw $365M. The vast majority of this fundraising occurred in the last 1-2 years.</li>
                <li style="margin-left:2em; padding-bottom: 0;">In the same time, $7.4B was invested in AI chips in China, $2.9B in the US, while all of Europe invested $446.7M combined.</li>
            </ol>
        </li>

        <h4>
            <b>What are the main barriers to investment/business uptake?</b>
        </h4>

        <p>
            <i><b>1. Enterprise adoption</b></i>
        </p>

        <li> 
            These are largely grouped around skills, privacy, and the need to finetune off-the-shelf models. 
        </li>

        <li>
            You may want to train your model to respond to customer requests or mark-up documents in a specific way, or provide it with confidential or proprietary information that‚Äôs not in its training data, but want to keep it ring-fenced within your organization. This requires time and a degree of technical expertise. 
        </li>

        <li>
            For example, in recent weeks, we‚Äôve seen OpenAI introduce <a href="https://openai.com/blog/introducing-chatgpt-enterprise" target="_blank">ChatGPT Enterprise</a>, which incorporates enterprise-grade privacy: conversations are encrypted and the models don‚Äôt learn from usage. 
        </li>

        <li>
            OpenAI has also partnered with Scale AI to provide <a href="https://openai.com/blog/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models" target="_blank">fine-tuning support</a> for businesses using GPT-3.5, with the intention of extending this to GPT-4.
        </li>

        <li>
            Over the years, I expect we‚Äôll see the emergence of a healthy market for fine-tuning support. 
        </li>

        <br>

        <p>
            <i><b>2. Investment</b></i>
        </p>

        <li> 
            Science and tech leadership ultimately doesn‚Äôt come cheap. 
        </li>

        <li>
            Government subsidy isn‚Äôt a long-term viable alternative to private investment - the UK is not short of accelerators and support schemes.
        </li>

        <li>
            Unfortunately, it feels like the government has been doing everything it can to deter investment in recent years, with international confidence in the UK hitting historic lows in recent years.
        </li>

        <li>
            To change this, we need three different things:

            <ol style="list-style-type: lower-alpha; padding-bottom: 0;">
                <li style="margin-left:2em"><b>Political stability:</b> as governments have changed in recent years, policy and priorities have varied significantly. Consistency, both on science and tech specifically, but economic policy more generally is essential.</li>
                <li style="margin-left:2em; padding-bottom: 0;"><b>A welcoming immigration system:</b> both in terms of actual policy and also tone. Talent needs to know that it will be able to move to this country, be made to feel welcome here, and not undergo a process that treats it with suspicion.</li>
                <li style="margin-left:2em"><b>Less hostility to the tech sector:</b> proposals that would break end-to-end encryption in legislation like the Online Safety Bill, or amendments to the Investigatory Powers Act that would give the Home Office oversight over smartphone upgrades, undermine international attempts to paint the UK as a serious technology power.</li>
            </ol>
        </li>



        <h4>
            <b>Regulatory intervention</b>
        </h4>

        <p>
            Note: read our essay in full <a href="https://www.airstreet.com/blog/uk-ai-safety-summit" target="_blank">here</a>.
        </p>

        <li> 
            At Air Street, we‚Äôve previously expressed our support for the UK‚Äôs approach to AI regulation. 
        </li>

        <li>
            We believe that AI is a general purpose technology, which means that AI risks will be context-dependent. As a result, we think the people who understand that context will be best-placed to identify and respond to the risks.
        </li>

        <li>
            Regulators like the ICO or the MHRA have existed for decades and navigated technological change. We would recommend helping them build out the expertise and capacity to respond to new challenges, rather than spinning up a series of new regulatory frameworks, many of which may be out-of-date quickly.
        </li>

        <li> 
            We saw this with the EU having to rewrite its AI Act at the last minute to incorporate foundation models. Static regulation is a bad way to respond to rapid change.  
        </li>

        <li>
            It‚Äôs important to avoid AI exceptionalism - we don‚Äôt normally heavily regulate things on the basis of hypothetical future risks, AI shouldn‚Äôt be any different.
        </li>

        <li>
            Premature regulation on the basis of safety fears is also bad for competition - that‚Äôs why big companies are happy to advocate for policies like licensing regimes, as they know they‚Äôll hamper open source model providers.
        </li>


        <h4>
            <b>Open vs closed source </b>
        </h4>

        <p>
            <i><b>The move away from open source</b></i>
        </p>

        <li> 
            I‚Äôm a great believer in open source and don‚Äôt believe that any of the frontier models that are likely to be open sourced in the near future are likely to be powerful enough to pose a serious safety risk.  
        </li>

        <li>
            We‚Äôve seen a relatively rapid move away from open source among the big labs (with Meta standing out as the obvious exception). While this has been framed as safety-motivated, I suspect commercial considerations are likely the main driver.
        </li>

        <li>
            Companies like OpenAI have invested huge sums of money in developing their technology and are now interested in commercializing it, rather than handing the instruction manual over to other people.
        </li>

        <br>

        <p>
            <i><b>How can the government facilitate an open source ecosystem?</b></i>
        </p>

        <li> 
            The biggest single barrier to smaller players is access to compute power. The government has outlined plans to build out public cloud capacity, but the current plans aren‚Äôt nearly ambitious enough. We currently have fewer than 1,000 GPUs available to researchers. 
        </li>

        <li>
            The Future of Compute Review recommended a 3,000 GPU target when some corporate labs already have 10x this capacity.

            <ol style="list-style-type: lower-alpha; padding-bottom: 0;">
                <li style="margin-left:2em">By contrast, Anthropic has suggested the US should invest $4 billion over three years to build a 100,000 GPU cluster.</li>
            </ol>
        </li>

        <li>
            Another obstacle is access to a high enough volume of training data. We could consider creating a national data bank.

            <ol style="list-style-type: lower-alpha; padding-bottom: 0;">
                <li style="margin-left:2em">It could bring together data from the BBC, government departments, our universities, and other sources for values-aligned UK companies looking to build LLMs.</li>
                <li style="margin-left:2em">But here, infrastructure investments are important - recall that DeepMind tried to revolutionize the NHS with AI and we ended up several years later with a task management app for clinicians.</li>
            </ol>
        </li>

        <li> 
            At the same time, we need to be clear-eyed about what‚Äôs possible - unless we see a sudden unexpected drop in compute costs or the emergence of a new less compute-intensive paradigm in AI research, the levers the government has at its disposal are only likely to make a difference around the margins. 
        </li>

        <li> 
            It‚Äôs essentially inevitable that only a few companies will create the most powerful models - in the same way that two companies design the operating systems used on the vast majority of the world‚Äôs computers. The competition will likely be much livelier in other parts of the value chain. 
        </li>

        <br>

        <p>
            <i><b>Liability</b></i>
        </p>

        <li> 
            Liability is unlikely to sit in one part of the value chain. It is obviously the responsibility of the developer to ensure that a model is trained on representative and ethically sourced data, that it‚Äôs resistant to adversarial attacks, and that it‚Äôs been subjected to appropriate auditing and testing before being released. 
        </li>

        <li> 
            At the same time, it is unreasonable to hold developers responsible for every downstream use of their system. If an operator finetunes a system badly or a user deliberately acts with malice - there‚Äôs only so much developers can do to prevent this from happening. 
        </li>

        <li> 
            There‚Äôs no other industry in the world that assigns all responsibility to the original creator of a piece of technology. If we don‚Äôt accept a degree of risk and personal responsibility, technological progress will stall entirely.
        </li>

      <footer class="site-footer">
        <span class="site-footer-credits">
          &copy; 2023 Air Street Capital Management Ltd., all rights reserved. 
          <p><a href="https://www.twitter.com/airstreet" target="_blank"><u>Twitter</u></a> | <a href="https://www.linkedin.com/company/airstreetcapital/" target="_blank"><u>LinkedIn</u></a></p>
      </footer>
    </section>
  </body>
</html>